{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd3f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73dedc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.1189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1      2      3      4       5       6       7       8       9   \\\n",
       "0  842302  M  17.99  10.38  122.8  1001.0  0.1184  0.2776  0.3001  0.1471   \n",
       "\n",
       "   ...     22     23     24      25      26      27      28      29      30  \\\n",
       "0  ...  25.38  17.33  184.6  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601   \n",
       "\n",
       "       31  \n",
       "0  0.1189  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Oblig1/wdbc.data\", header=None)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae77ae8",
   "metadata": {},
   "source": [
    "beskriv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55411b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = np.where(df[1] == \"M\", 1, 0)\n",
    "df = df.drop([0,1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a790f4",
   "metadata": {},
   "source": [
    "Før vi bruker datasete videre konvertere vi verdiene i target kollonen til 1 for M og 0 for B, slik at disse er på et format som kan brukes senere, videre legger vi disse verdiene i en ny kollone \"target\", slik at vi letter kan bruke generelle funksjoner for splitting av datasetet. Siden verdiene for ID kollonen og den gamle kollonen for target verdiene ikke har noe videre nytteverdi, så dropper vi disse dra datasetet.\n",
    "\n",
    "ref for np.where: https://www.geeksforgeeks.org/numpy/numpy-where-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9e5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funksjon for splitting av dataset i train, validate og test\n",
    "def split_dataset(data):\n",
    "    train_val = data.groupby(\"target\", group_keys=False)[data.columns].sample(frac=0.8)\n",
    "    test = data.drop(train_val.index)\n",
    "    train = train_val.groupby(\"target\", group_keys=False)[train_val.columns].sample(frac=0.75)\n",
    "    validation = train_val.drop(train.index)    \n",
    "    return [train, validation, test]\n",
    "\n",
    "# hjelpe funksjon for å validere av jevn fordeling av dataset på target verdi\n",
    "def check_split_dataset(data):\n",
    "    print(data[0][\"target\"].value_counts()/data[0].shape[0])\n",
    "    print(data[1][\"target\"].value_counts()/data[1].shape[0])\n",
    "    print(data[2][\"target\"].value_counts()/data[2].shape[0])\n",
    "\n",
    "# funksjon for å dele opp i targets og features\n",
    "def split_targets_and_features(data):\n",
    "    targets = data.target\n",
    "    features = data.drop(\"target\", axis=1)\n",
    "    return [targets, features]\n",
    "\n",
    "# hjelpe funksjon for oppdeling i features og targets\n",
    "def create_set_of_targets_and_features(data):\n",
    "    train = split_targets_and_features(data[0])\n",
    "    validation = split_targets_and_features(data[1])\n",
    "    test = split_targets_and_features(data[2])\n",
    "\n",
    "    return [train, validation, test]\n",
    "\n",
    "# funksjon for spliting av dataset\n",
    "def create_full_dataset(input):\n",
    "    data = split_dataset(input)\n",
    "    dataset = create_set_of_targets_and_features(data)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655f4e24",
   "metadata": {},
   "source": [
    "I seksjonen over så ligger kode for alle fuksjonene som brukes til å splitte opp datasettet.\n",
    "Jeg har valgt å bruke en 60, 20, 20 % split, slik at jeg får en god fordeling mellom dataene for trening, validering og testing. Ut ifra størelsen på dette datasette mener jeg dette gir en grei balangse mellom nok data til trening av moddelen, men samtidig nok data til opptimalisering og testing av moddelen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15413364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hjelpe fuksjon for vurdering av modellene        \n",
    "def evaluate_model(classifier, features, targets):\n",
    "    predictions = classifier.predict(features)\n",
    "    accuracy = accuracy_score(targets, predictions)\n",
    "    precision = precision_score(targets, predictions)\n",
    "    recall = recall_score(targets, predictions)\n",
    "    f1 = f1_score(targets, predictions)\n",
    "    roc_auc = roc_auc_score(targets, predictions)   \n",
    "\n",
    "    return [accuracy, precision, recall, f1, roc_auc]\n",
    "\n",
    "# hjelpe funksjon for å legg til verdier i resultat array i validate og test funksjonen \n",
    "def append_values(results, accuracy, precision, recall, f1, roc_auc):\n",
    "        accuracy.append(results[0])\n",
    "        precision.append(results[1])\n",
    "        recall.append(results[2])\n",
    "        f1.append(results[3])\n",
    "        roc_auc.append(results[4])\n",
    "\n",
    "# hjelpe funksjon for å printe resultatene fra validate funksjonen\n",
    "def results_print(accuracy, precision, recall, f1, roc_auc):\n",
    "    print(f'Accuracy: {np.mean(accuracy):.2f}')\n",
    "    print(f'Precision: {np.mean(precision):.2f}')\n",
    "    print(f'Recall: {np.mean(recall):.2f}')\n",
    "    print(f'F1: {np.mean(f1):.2f}')\n",
    "    print(f'ROCAUC: {np.mean(roc_auc):.2f}')\n",
    "\n",
    "# hjelpe funksjon for å printe resultatene fra test funksjonen\n",
    "def test_results_print(accuracy, precision, recall, f1, roc_auc):\n",
    "    print(f'Accuracy: {np.mean(accuracy):.2f} +- {np.std(accuracy):.2f}')\n",
    "    print(f'Precision: {np.mean(precision):.2f} +- {np.std(precision):.2f}')\n",
    "    print(f'Recall: {np.mean(recall):.2f} +- {np.std(recall):.2f}')\n",
    "    print(f'F1: {np.mean(f1):.2f} +- {np.std(f1):.2f}')\n",
    "    print(f'ROCAUC: {np.mean(roc_auc):.2f} +- {np.std(roc_auc):.2f}')\n",
    "\n",
    "# funksjon for å validere modellene og hyperparameter tuningen\n",
    "def validate(classifier):    \n",
    "    train_accuracy, train_precision, train_recall, train_f1, train_roc_auc = [], [], [], [], []\n",
    "    validate_accuracy, validate_precision, validate_recall, validate_f1, validate_roc_auc = [], [], [], [], []\n",
    "\n",
    "    for i in range(0, 20, 1):\n",
    "        dataset = create_full_dataset(df)\n",
    "        classifier.fit(dataset[0][1], dataset[0][0])\n",
    "    \n",
    "        results_train = evaluate_model(classifier, dataset[0][1], dataset[0][0])\n",
    "        append_values(results_train, train_accuracy, train_precision, train_recall, train_f1, train_roc_auc)\n",
    "    \n",
    "        results_validate = evaluate_model(classifier, dataset[1][1], dataset[1][0])\n",
    "        append_values(results_validate, validate_accuracy, validate_precision, validate_recall, validate_f1, validate_roc_auc)\n",
    "\n",
    "    print('Training results:')\n",
    "    results_print(train_accuracy, train_precision, train_recall, train_f1, train_roc_auc)\n",
    "    print('Validation results:')\n",
    "    results_print(validate_accuracy, validate_precision, validate_recall, validate_f1, validate_roc_auc)\n",
    "\n",
    "# funksjon for endelig testing av modellene og hyperparameter tuningen\n",
    "def test(classifier):\n",
    "    accuracy, precision, recall, f1, roc_auc = [], [], [], [], []\n",
    "\n",
    "    for i in range(0, 20, 1):\n",
    "        dataset = create_full_dataset(df)\n",
    "        classifier.fit(dataset[0][1], dataset[0][0])\n",
    "\n",
    "        results = evaluate_model(classifier, dataset[2][1], dataset[2][0])\n",
    "        append_values(results, accuracy, precision, recall, f1, roc_auc)\n",
    "    \n",
    "    print('Test results:')\n",
    "    test_results_print(accuracy, precision, recall, f1, roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2861fa2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74c20907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1: 1.00\n",
      "ROCAUC: 1.00\n",
      "Validation results:\n",
      "Accuracy: 0.92\n",
      "Precision: 0.90\n",
      "Recall: 0.90\n",
      "F1: 0.90\n",
      "ROCAUC: 0.92\n",
      "Test results:\n",
      "Accuracy: 0.92 +- 0.03\n",
      "Precision: 0.91 +- 0.04\n",
      "Recall: 0.88 +- 0.05\n",
      "F1: 0.90 +- 0.04\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt1 = DecisionTreeClassifier()\n",
    "validate(dt1)\n",
    "test(dt1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3433440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.95\n",
      "Precision: 0.96\n",
      "Recall: 0.90\n",
      "F1: 0.93\n",
      "ROCAUC: 0.94\n",
      "Validation results:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.94\n",
      "Recall: 0.88\n",
      "F1: 0.91\n",
      "ROCAUC: 0.92\n",
      "Test results:\n",
      "Accuracy: 0.94 +- 0.02\n",
      "Precision: 0.93 +- 0.02\n",
      "Recall: 0.90 +- 0.06\n",
      "F1: 0.91 +- 0.03\n",
      "ROCAUC: 0.93 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "nb1 = GaussianNB(var_smoothing=1e-9)\n",
    "validate(nb1)\n",
    "test(nb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3658d3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.96\n",
      "Recall: 0.87\n",
      "F1: 0.91\n",
      "ROCAUC: 0.92\n",
      "Validation results:\n",
      "Accuracy: 0.93\n",
      "Precision: 0.95\n",
      "Recall: 0.85\n",
      "F1: 0.90\n",
      "ROCAUC: 0.91\n"
     ]
    }
   ],
   "source": [
    "nb1 = GaussianNB(var_smoothing=1e-8)\n",
    "validate(nb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8328f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.93\n",
      "Precision: 0.97\n",
      "Recall: 0.84\n",
      "F1: 0.90\n",
      "ROCAUC: 0.91\n",
      "Validation results:\n",
      "Accuracy: 0.93\n",
      "Precision: 0.97\n",
      "Recall: 0.84\n",
      "F1: 0.90\n",
      "ROCAUC: 0.91\n"
     ]
    }
   ],
   "source": [
    "nb1 = GaussianNB(var_smoothing=1e-7)\n",
    "validate(nb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91fed950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.94\n",
      "Recall: 0.89\n",
      "F1: 0.91\n",
      "ROCAUC: 0.93\n",
      "Validation results:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.93\n",
      "Recall: 0.89\n",
      "F1: 0.91\n",
      "ROCAUC: 0.93\n"
     ]
    }
   ],
   "source": [
    "nb1 = GaussianNB(var_smoothing=1e-10)\n",
    "validate(nb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88dc8fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.94\n",
      "Recall: 0.90\n",
      "F1: 0.92\n",
      "ROCAUC: 0.93\n",
      "Validation results:\n",
      "Accuracy: 0.93\n",
      "Precision: 0.91\n",
      "Recall: 0.90\n",
      "F1: 0.90\n",
      "ROCAUC: 0.92\n",
      "Test results:\n",
      "Accuracy: 0.93 +- 0.03\n",
      "Precision: 0.91 +- 0.05\n",
      "Recall: 0.89 +- 0.05\n",
      "F1: 0.90 +- 0.04\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "nb1 = GaussianNB(var_smoothing=1e-14)\n",
    "validate(nb1)\n",
    "test(nb1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
