{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b760138",
   "metadata": {},
   "source": [
    "I forhold til utdyping av forklaring av kode, samt valg av metodik så legger jeg en markdown seksjon under den akkutelle kode seksjonen, i noen tillfeller vil jeg legge denne forklarende seksjonen slik at den forklarer flere ovenforliggende kode seksjoner der hvor det er mest hensiksmessig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd3f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73dedc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"../Oblig1/wdbc.data\", header=None)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6945e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0           2           3           4            5   \\\n",
       "count  5.690000e+02  569.000000  569.000000  569.000000   569.000000   \n",
       "mean   3.037183e+07   14.127292   19.289649   91.969033   654.889104   \n",
       "std    1.250206e+08    3.524049    4.301036   24.298981   351.914129   \n",
       "min    8.670000e+03    6.981000    9.710000   43.790000   143.500000   \n",
       "25%    8.692180e+05   11.700000   16.170000   75.170000   420.300000   \n",
       "50%    9.060240e+05   13.370000   18.840000   86.240000   551.100000   \n",
       "75%    8.813129e+06   15.780000   21.800000  104.100000   782.700000   \n",
       "max    9.113205e+08   28.110000   39.280000  188.500000  2501.000000   \n",
       "\n",
       "               6           7           8           9           10  ...  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  ...   \n",
       "mean     0.096360    0.104341    0.088799    0.048919    0.181162  ...   \n",
       "std      0.014064    0.052813    0.079720    0.038803    0.027414  ...   \n",
       "min      0.052630    0.019380    0.000000    0.000000    0.106000  ...   \n",
       "25%      0.086370    0.064920    0.029560    0.020310    0.161900  ...   \n",
       "50%      0.095870    0.092630    0.061540    0.033500    0.179200  ...   \n",
       "75%      0.105300    0.130400    0.130700    0.074000    0.195700  ...   \n",
       "max      0.163400    0.345400    0.426800    0.201200    0.304000  ...   \n",
       "\n",
       "               22          23          24           25          26  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "               27          28          29          30          31  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b20eaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       569 non-null    int64  \n",
      " 1   1       569 non-null    object \n",
      " 2   2       569 non-null    float64\n",
      " 3   3       569 non-null    float64\n",
      " 4   4       569 non-null    float64\n",
      " 5   5       569 non-null    float64\n",
      " 6   6       569 non-null    float64\n",
      " 7   7       569 non-null    float64\n",
      " 8   8       569 non-null    float64\n",
      " 9   9       569 non-null    float64\n",
      " 10  10      569 non-null    float64\n",
      " 11  11      569 non-null    float64\n",
      " 12  12      569 non-null    float64\n",
      " 13  13      569 non-null    float64\n",
      " 14  14      569 non-null    float64\n",
      " 15  15      569 non-null    float64\n",
      " 16  16      569 non-null    float64\n",
      " 17  17      569 non-null    float64\n",
      " 18  18      569 non-null    float64\n",
      " 19  19      569 non-null    float64\n",
      " 20  20      569 non-null    float64\n",
      " 21  21      569 non-null    float64\n",
      " 22  22      569 non-null    float64\n",
      " 23  23      569 non-null    float64\n",
      " 24  24      569 non-null    float64\n",
      " 25  25      569 non-null    float64\n",
      " 26  26      569 non-null    float64\n",
      " 27  27      569 non-null    float64\n",
      " 28  28      569 non-null    float64\n",
      " 29  29      569 non-null    float64\n",
      " 30  30      569 non-null    float64\n",
      " 31  31      569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae77ae8",
   "metadata": {},
   "source": [
    "Ut i fra beskrivelsen til datasetet er hensikten å analysere forskjellige features for for å se om vi kan lage en modell predikere om en sulst er malignant (M) eller benign (B). Datasetet består av en id kollone (index 0), en target verdi (index 1) som enten er M eller B og de resterende kollonene er features. Alle features verdiene ser ut til å være normalfordelte float verdier. Det vil derfor være hensiktsmessig å bruke stratified sampling på dette datasette slik at vi oppnår en tilnærmet lik fordeling for target variablen mellom de forskjellige datasettene vi deler opp i. Videre vil det være hensikts messig å bruke en naive bayes modell for normalfordelte data og jeg kommer derfor til å bruke GaussianNB for naive bayes delen av analysen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55411b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2      3       4       5        6        7       8        9      10  \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        11  ...     23      24      25      26      27      28      29  \\\n",
       "0  0.07871  ...  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  target  \n",
       "0  0.4601  0.11890       1  \n",
       "1  0.2750  0.08902       1  \n",
       "2  0.3613  0.08758       1  \n",
       "3  0.6638  0.17300       1  \n",
       "4  0.2364  0.07678       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_df.copy()\n",
    "df[\"target\"] = np.where(df[1] == \"M\", 1, 0)\n",
    "df = df.drop([0,1], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a790f4",
   "metadata": {},
   "source": [
    "Før vi bruker datasete videre må vi konvertere verdiene i target kollonen slik at disse kan brukes med de verktøyene vi ønsker å bruke. Jeg har gjort dette ved å bruke numpy.where() fuksjonen til å konvertere verdien M til 1 og B til 0. Videre har jeg lagt disse verdiene i en ny kollone \"target\", slik at det letter kan brukes generelle funksjoner for splitting av datasetet. Siden verdiene for ID kollonen og den gamle kollonen for target verdiene ikke har noe videre nytteverdi, så dropper vi disse fra datasetet.\n",
    "\n",
    "ref for np.where: https://www.geeksforgeeks.org/numpy/numpy-where-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9e5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funksjon for splitting av dataset i train, validate og test\n",
    "def split_dataset(data):\n",
    "    train_val = data.groupby(\"target\", group_keys=False)[data.columns].sample(frac=0.8)\n",
    "    test = data.drop(train_val.index)\n",
    "    train = train_val.groupby(\"target\", group_keys=False)[train_val.columns].sample(frac=0.75)\n",
    "    validation = train_val.drop(train.index)    \n",
    "    return [train, validation, test]\n",
    "\n",
    "# hjelpe funksjon for å validere av jevn fordeling av dataset på target verdi\n",
    "def check_split_dataset(data):\n",
    "    print(data[0][\"target\"].value_counts()/data[0].shape[0])\n",
    "    print(data[1][\"target\"].value_counts()/data[1].shape[0])\n",
    "    print(data[2][\"target\"].value_counts()/data[2].shape[0])\n",
    "\n",
    "# funksjon for å dele opp i targets og features\n",
    "def split_targets_and_features(data):\n",
    "    targets = data.target\n",
    "    features = data.drop(\"target\", axis=1)\n",
    "    return [targets, features]\n",
    "\n",
    "# hjelpe funksjon for oppdeling i features og targets\n",
    "def create_set_of_targets_and_features(data):\n",
    "    train = split_targets_and_features(data[0])\n",
    "    validation = split_targets_and_features(data[1])\n",
    "    test = split_targets_and_features(data[2])\n",
    "\n",
    "    return [train, validation, test]\n",
    "\n",
    "# funksjon for spliting av dataset\n",
    "def create_full_dataset(input):\n",
    "    data = split_dataset(input)\n",
    "    dataset = create_set_of_targets_and_features(data)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a62298a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    0.625731\n",
      "1    0.374269\n",
      "Name: count, dtype: float64\n",
      "target\n",
      "0    0.631579\n",
      "1    0.368421\n",
      "Name: count, dtype: float64\n",
      "target\n",
      "0    0.628319\n",
      "1    0.371681\n",
      "Name: count, dtype: float64\n",
      "**********\n",
      "0.6010544815465729\n",
      "0.20035149384885764\n",
      "0.19859402460456943\n"
     ]
    }
   ],
   "source": [
    "test_dataset = split_dataset(df)\n",
    "check_split_dataset(test_dataset)\n",
    "print('**********')\n",
    "print(test_dataset[0].shape[0]/df.target.shape[0])\n",
    "print(test_dataset[1].shape[0]/df.target.shape[0])\n",
    "print(test_dataset[2].shape[0]/df.target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655f4e24",
   "metadata": {},
   "source": [
    "Som nevn tidligere jeg har valgt å bruke stratified sampling med grupering på target kollonen slik at det oppnås en tilnærmet lik fordeling for utfallet av target hendelsen mellom de forskjellige delene av datasetet. Videre har jeg delt opp datasetet i 60, 20, 20 % split for henholdsvis training, validation og testing, slik at jeg får en god fordeling mellom dataene for trening, validering og testing. Ut ifra størelsen på datasette og typen target variabel det inneholder mener jeg dette gir en grei balanse mellom nok data til trening av modellen, men samtidig en god mengde data til opptimalisering og testing av modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15413364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hjelpe fuksjon for vurdering av modellene        \n",
    "def evaluate_model(classifier, features, targets):\n",
    "    predictions = classifier.predict(features)\n",
    "    accuracy = accuracy_score(targets, predictions)\n",
    "    precision = precision_score(targets, predictions)\n",
    "    recall = recall_score(targets, predictions)\n",
    "    f1 = f1_score(targets, predictions)\n",
    "    roc_auc = roc_auc_score(targets, predictions)   \n",
    "\n",
    "    return [accuracy, precision, recall, f1, roc_auc]\n",
    "\n",
    "# hjelpe funksjon for å legg til verdier i resultat array i validate og test funksjonen \n",
    "def append_values(results, accuracy, precision, recall, f1, roc_auc):\n",
    "        accuracy.append(results[0])\n",
    "        precision.append(results[1])\n",
    "        recall.append(results[2])\n",
    "        f1.append(results[3])\n",
    "        roc_auc.append(results[4])\n",
    "\n",
    "# hjelpe funksjon for å printe resultatene fra validate funksjonen\n",
    "def results_print(accuracy, precision, recall, f1, roc_auc):\n",
    "    print(f'Accuracy: {np.mean(accuracy):.2f} +- {np.std(accuracy):.2f}')\n",
    "    print(f'Precision: {np.mean(precision):.2f} +- {np.std(precision):.2f}')\n",
    "    print(f'Recall: {np.mean(recall):.2f} +- {np.std(recall):.2f}')\n",
    "    print(f'F1: {np.mean(f1):.2f} +- {np.std(f1):.2f}')\n",
    "    print(f'ROCAUC: {np.mean(roc_auc):.2f} +- {np.std(roc_auc):.2f}')\n",
    "\n",
    "# funksjon for å trening og hyperparameter tuning av modellen med mulighet intern looping i fuksjonen.\n",
    "def validate(classifier, runs):    \n",
    "    train_accuracy, train_precision, train_recall, train_f1, train_roc_auc = [], [], [], [], []\n",
    "    validate_accuracy, validate_precision, validate_recall, validate_f1, validate_roc_auc = [], [], [], [], []\n",
    "\n",
    "    if(runs < 1): runs = 1\n",
    "\n",
    "    for i in range(0, runs, 1):\n",
    "        dataset = create_full_dataset(df)\n",
    "        classifier.fit(dataset[0][1], dataset[0][0])\n",
    "    \n",
    "        results_train = evaluate_model(classifier, dataset[0][1], dataset[0][0])\n",
    "        append_values(results_train, train_accuracy, train_precision, train_recall, train_f1, train_roc_auc)\n",
    "    \n",
    "        results_validate = evaluate_model(classifier, dataset[1][1], dataset[1][0])\n",
    "        append_values(results_validate, validate_accuracy, validate_precision, validate_recall, validate_f1, validate_roc_auc)\n",
    "    \n",
    "    print('Training results:')\n",
    "    results_print(train_accuracy, train_precision, train_recall, train_f1, train_roc_auc)\n",
    "    print('************************')\n",
    "    print('Validation results:')\n",
    "    results_print(validate_accuracy, validate_precision, validate_recall, validate_f1, validate_roc_auc)\n",
    "\n",
    "# funksjon for endelig testing av modellene med mulighet intern looping av fuksjonen.\n",
    "def test(classifier, runs):\n",
    "    accuracy, precision, recall, f1, roc_auc = [], [], [], [], []\n",
    "\n",
    "    if(runs < 1): runs = 1\n",
    "\n",
    "    for i in range(0, runs, 1):\n",
    "        dataset = create_full_dataset(df)\n",
    "        classifier.fit(dataset[0][1], dataset[0][0])\n",
    "\n",
    "        results = evaluate_model(classifier, dataset[2][1], dataset[2][0])\n",
    "        append_values(results, accuracy, precision, recall, f1, roc_auc)\n",
    "    print('************************')\n",
    "    print('Test results:')\n",
    "    results_print(accuracy, precision, recall, f1, roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2861fa2",
   "metadata": {},
   "source": [
    "For funksjonene jeg har laget for trening, tuning og testing av modellen så har jeg valgt å legg inn løkker, slik at validering og testing kan kjøres flere gang med ny oppdeling av datasetet hver gang disse løkkene starter på en ny loop. Dette er gjort for å oppnå mindre variasjon i resultatene ved både validering av tuningen, samt testing av slutt resultatet slik at disse har større grad av pålitelighet. Jeg har også lagt inn mulighet for å velg antall ganger løkkene skal kjøres.\n",
    "\n",
    "Videre er det gjennomsnittet av resultatene fra alle kjøringene i løkkene som skrive ut sammen med standardavik, slik at dette gir et bedre bilde av variasjonen som oppstår pga. den randomiserte oppdeling av datasettet ved bruk av løkkene i testingen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec25049",
   "metadata": {},
   "source": [
    "For å vurdere modellen underveis i trenings og validerings prossesen har jeg valgt å bruke følgende målinger, accuracy, precision, recall, f1_score og roc_auc_score. Accuracy er et mål på hvor treffsiker modellen er og vurderes ved å sette antalle riktige prediksjoner opp mot det totale antallet av prediksjoner [2]. Precision er et mål hvor presis modellen er til å predikere \"positive\" utfall, dette vurderes ved å sett antall riktige \"positive\" prediksjoner opp mot totalen av \"positive\" prediksjoner [2]. Recall er et mål på hvor god modellen er til å finne alle \"positive\" utfall, dette vurderes ved å sette antall riktige \"positive\" prediksjoner opp mot totalen av antall riktig \"positive\" prediksjon pluss antallet falske \"negavtive\" prediksjoner [2]. f1_score er et mål på balansen mellom precision og recall og gir deg dermed et mål på hvor balanser modellen er på å være presis i sine prediksjoner, men samtidig oppdage/predikere så mange som mulig \"positive\" utfall [2]. roc er et mål på riktig \"positive\" prediksjon mot falske \"positive\" prediksjon og roc_auc_score gir deg en verdi for total arealet under roc curven til modellen. Et resultat på denne på 0.5 sier at modellen ikke er noe bedre enn randomisert tilfeldig tilfeller, mens 1.0 tilsier et perfekt resultat. roc_auc_score er derfor en god indikator på forholdet mellom riktige og falske positive prediksjoner [2] [3]. \n",
    "\n",
    "ref:\n",
    "[2] (tuning parameter): \"https://scikit-learn.org/stable/modules/model_evaluation.html\", lest 20.09.25\n",
    "\n",
    "[3] (roc_auc): https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve, lest 19.09.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c20907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 1.00 +- 0.00\n",
      "Precision: 1.00 +- 0.00\n",
      "Recall: 1.00 +- 0.00\n",
      "F1: 1.00 +- 0.00\n",
      "ROCAUC: 1.00 +- 0.00\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.92 +- 0.03\n",
      "Precision: 0.89 +- 0.05\n",
      "Recall: 0.91 +- 0.05\n",
      "F1: 0.90 +- 0.04\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt1 = DecisionTreeClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2)\n",
    "validate(dt1, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55cc24c",
   "metadata": {},
   "source": [
    "Før hyperparameter tuning av DecisionTreeClassifier modellen kjører vi en validering med defaulte instillinger for å få oss en baseline vi kan sammenligne med. Når vi ser på de første resultatene ser vi at trenings delen av resultatene gir full utelling på alle test variablene vi har satt opp, mens det for validerings delen ikke gir like gode resultater. Dette forteller oss at modellen har et problem med overfiting i forhold til trenings delen av datasette som dermed gir en dårligere gennerell overføringsverdi av modellen. Det er derfor ønskelig å tune modellen for å prøve å oppnå en bedre generell overføringsverdi og mindre overfiting av modellen [4].\n",
    "\n",
    "I forhold til tuning av modellen har jeg valg å bruke max_depth, min_samples_leaf og min_samples_split. Grunnen til at jeg har valg disse tuning parameterene er at disse gir oss en god mulighet til redusere eventuell overfitting og derfor gjøre slik at modellen er mer genereliset overførbar til andre data en det den er trent på. \n",
    "For max_depth skjer dette ved å begrese maks dybden treet til modellen kan ha og derfor begresen muligheten modellen har til å tilpasse seg spesille utliggere eller edge caser. For min_samples_leaf skjer dette ved å spesifisere minimums antallet av verdier/hendelser som en bladnode kan inneholde og dermed kan du begrense muligheten til modellen å innehold bladnode med veldig få verdier. Vidre for min_samples_split så tunes modellen ved å sette en begrensning på antall verdier en node må innehold for å kunne splites, dette gjør dermed at du kan unngå oppdeling av noder som innehold få verdier [4].\n",
    "\n",
    "ref: \n",
    "[4]: \"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\", lest 20.09.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a8a8231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 1.00 +- 0.00\n",
      "Precision: 1.00 +- 0.00\n",
      "Recall: 1.00 +- 0.00\n",
      "F1: 1.00 +- 0.00\n",
      "ROCAUC: 1.00 +- 0.00\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.90 +- 0.03\n",
      "Recall: 0.91 +- 0.06\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt2 = DecisionTreeClassifier(max_depth=10, min_samples_leaf=1, min_samples_split=2)\n",
    "validate(dt2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da22c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 1.00 +- 0.00\n",
      "Precision: 1.00 +- 0.00\n",
      "Recall: 0.99 +- 0.01\n",
      "F1: 0.99 +- 0.00\n",
      "ROCAUC: 0.99 +- 0.00\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.03\n",
      "Precision: 0.90 +- 0.04\n",
      "Recall: 0.90 +- 0.06\n",
      "F1: 0.90 +- 0.04\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt3 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=1, min_samples_split=2)\n",
    "validate(dt3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46c2cfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.98 +- 0.01\n",
      "Precision: 0.99 +- 0.01\n",
      "Recall: 0.95 +- 0.02\n",
      "F1: 0.97 +- 0.01\n",
      "ROCAUC: 0.97 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.93 +- 0.05\n",
      "Recall: 0.88 +- 0.06\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt4 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=1, min_samples_split=2)\n",
    "validate(dt4, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7e0515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.96 +- 0.01\n",
      "Precision: 0.95 +- 0.03\n",
      "Recall: 0.93 +- 0.04\n",
      "F1: 0.94 +- 0.01\n",
      "ROCAUC: 0.95 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.92 +- 0.03\n",
      "Precision: 0.91 +- 0.06\n",
      "Recall: 0.89 +- 0.05\n",
      "F1: 0.89 +- 0.04\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt5 = DecisionTreeClassifier(max_depth=2, min_samples_leaf=1, min_samples_split=2)\n",
    "validate(dt5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39fa1825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.99 +- 0.01\n",
      "Precision: 0.99 +- 0.01\n",
      "Recall: 0.98 +- 0.01\n",
      "F1: 0.99 +- 0.01\n",
      "ROCAUC: 0.99 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.91 +- 0.04\n",
      "Recall: 0.90 +- 0.05\n",
      "F1: 0.91 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt6 = DecisionTreeClassifier(max_depth=4, min_samples_leaf=1, min_samples_split=2)\n",
    "validate(dt6, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25681268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.97 +- 0.01\n",
      "Precision: 0.98 +- 0.01\n",
      "Recall: 0.94 +- 0.02\n",
      "F1: 0.96 +- 0.01\n",
      "ROCAUC: 0.96 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.03\n",
      "Precision: 0.92 +- 0.04\n",
      "Recall: 0.89 +- 0.05\n",
      "F1: 0.91 +- 0.04\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt7 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=2)\n",
    "validate(dt7, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d53c6bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.96 +- 0.01\n",
      "Precision: 0.96 +- 0.02\n",
      "Recall: 0.93 +- 0.02\n",
      "F1: 0.94 +- 0.01\n",
      "ROCAUC: 0.95 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.91 +- 0.05\n",
      "Recall: 0.90 +- 0.04\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "dt8 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=10, min_samples_split=2)\n",
    "validate(dt8, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9694904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.97 +- 0.01\n",
      "Precision: 0.98 +- 0.02\n",
      "Recall: 0.93 +- 0.02\n",
      "F1: 0.95 +- 0.01\n",
      "ROCAUC: 0.96 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.92 +- 0.06\n",
      "Recall: 0.90 +- 0.05\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "dt9 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=10)\n",
    "validate(dt9, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e9b156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.97 +- 0.01\n",
      "Precision: 0.98 +- 0.02\n",
      "Recall: 0.93 +- 0.02\n",
      "F1: 0.95 +- 0.01\n",
      "ROCAUC: 0.96 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.93 +- 0.04\n",
      "Recall: 0.90 +- 0.05\n",
      "F1: 0.91 +- 0.03\n",
      "ROCAUC: 0.93 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "dt10 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=8)\n",
    "validate(dt10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28653634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.97 +- 0.01\n",
      "Precision: 0.98 +- 0.02\n",
      "Recall: 0.94 +- 0.02\n",
      "F1: 0.96 +- 0.01\n",
      "ROCAUC: 0.96 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.92 +- 0.04\n",
      "Recall: 0.89 +- 0.05\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "dt11 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=6)\n",
    "validate(dt11, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99e964b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.97 +- 0.01\n",
      "Precision: 0.98 +- 0.02\n",
      "Recall: 0.94 +- 0.02\n",
      "F1: 0.96 +- 0.01\n",
      "ROCAUC: 0.97 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.92 +- 0.02\n",
      "Precision: 0.91 +- 0.05\n",
      "Recall: 0.87 +- 0.05\n",
      "F1: 0.89 +- 0.03\n",
      "ROCAUC: 0.91 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "dt12 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=3, min_samples_split=8)\n",
    "validate(dt12, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b21f607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.97 +- 0.01\n",
      "Precision: 0.98 +- 0.02\n",
      "Recall: 0.94 +- 0.02\n",
      "F1: 0.96 +- 0.01\n",
      "ROCAUC: 0.96 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.92 +- 0.04\n",
      "Recall: 0.88 +- 0.05\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt13 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=4, min_samples_split=8)\n",
    "validate(dt13, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ead9c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.97 +- 0.01\n",
      "Precision: 0.97 +- 0.02\n",
      "Recall: 0.93 +- 0.03\n",
      "F1: 0.95 +- 0.01\n",
      "ROCAUC: 0.96 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.93 +- 0.04\n",
      "Recall: 0.88 +- 0.04\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "dt14 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=6, min_samples_split=10)\n",
    "validate(dt14, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2f7981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.96 +- 0.01\n",
      "Precision: 0.97 +- 0.02\n",
      "Recall: 0.93 +- 0.02\n",
      "F1: 0.95 +- 0.01\n",
      "ROCAUC: 0.96 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.91 +- 0.05\n",
      "Recall: 0.89 +- 0.05\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "dt15 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=6, min_samples_split=15)\n",
    "validate(dt15, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c081c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.97 +- 0.01\n",
      "Precision: 0.97 +- 0.02\n",
      "Recall: 0.96 +- 0.02\n",
      "F1: 0.97 +- 0.01\n",
      "ROCAUC: 0.97 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.90 +- 0.05\n",
      "Recall: 0.91 +- 0.05\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt16 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, min_samples_split=8)\n",
    "validate(dt16, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "076ebab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.97 +- 0.01\n",
      "Precision: 0.97 +- 0.01\n",
      "Recall: 0.96 +- 0.02\n",
      "F1: 0.96 +- 0.01\n",
      "ROCAUC: 0.97 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.03\n",
      "Precision: 0.91 +- 0.05\n",
      "Recall: 0.90 +- 0.05\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt17 = DecisionTreeClassifier(max_depth=4, min_samples_leaf=5, min_samples_split=8)\n",
    "validate(dt17, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "576190bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.98 +- 0.01\n",
      "Precision: 0.98 +- 0.02\n",
      "Recall: 0.96 +- 0.02\n",
      "F1: 0.97 +- 0.01\n",
      "ROCAUC: 0.97 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.92 +- 0.03\n",
      "Precision: 0.90 +- 0.05\n",
      "Recall: 0.89 +- 0.06\n",
      "F1: 0.90 +- 0.04\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "dt18 = DecisionTreeClassifier(max_depth=6, min_samples_leaf=5, min_samples_split=8)\n",
    "validate(dt18, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da0703",
   "metadata": {},
   "source": [
    "Etter å ha gjennomført testing og validering med forskjellige verdier for parameterene kom jeg fram til at versjonen \"dt10\" ga meg best resultater sammenlignet med baseline og det er dermed denne jeg kommer til å sammeligne opp mot GaussianNB for naive bayes modellen. dt10 hadde følge verdier for parameterene DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=8).\n",
    "\n",
    "Når vi sammenligner resultatene (se kopi av verdiene under), så ser vi at resultatene fra traning delen av datasetet har blitt dårligere fra dt1 til dt10, mens validerings delen har blitt noe forbedre. Samtidig har standard aviket økt for trenings delen og blitt minimalt mindre for validerings delen av datasete. Dette tyder i utgangspunktet på at modellen i mindre grad overfiter og potensielt har fått bedre generell overføringverdi. Det er imidlertid viktig å påpeke at det er en del variasjon i den randomiserte oppdelingen av datasete og du vil få forskjellige resultater ved repetive kjøringer av modellen, men helheten av resultatene tyder på at modellen har blitt bedre med tuningen fra dt1 til dt10.\n",
    "\n",
    "Når vi sammenligner de individuelle verdiene så ser vi at alle målene har blitt forbedret for validerings delen fra dt1 til dt10 bortsett fra for recall hvor det var en liten nedgang fra 0.91 til 0.90. Dette betyr i utgangspunktet at modellen har blitt bedre og mere presis i sine prediksjon, men litt dårligere til finne flest mulig ekte \"postive\" utfall. I dette tilfellet vil jeg alikvel si at den tunede modellen er totaltsett bedre enn den var ved baseline.\n",
    "\n",
    "dt1 (baseline):\n",
    "Training results:\n",
    "Accuracy: 1.00 +- 0.00\n",
    "Precision: 1.00 +- 0.00\n",
    "Recall: 1.00 +- 0.00\n",
    "F1: 1.00 +- 0.00\n",
    "ROCAUC: 1.00 +- 0.00\n",
    "************************\n",
    "Validation results:\n",
    "Accuracy: 0.92 +- 0.03\n",
    "Precision: 0.89 +- 0.05\n",
    "Recall: 0.91 +- 0.05\n",
    "F1: 0.90 +- 0.04\n",
    "ROCAUC: 0.92 +- 0.03\n",
    "\n",
    "dt10:\n",
    "Training results:\n",
    "Accuracy: 0.97 +- 0.01\n",
    "Precision: 0.98 +- 0.02\n",
    "Recall: 0.93 +- 0.02\n",
    "F1: 0.95 +- 0.01\n",
    "ROCAUC: 0.96 +- 0.01\n",
    "************************\n",
    "Validation results:\n",
    "Accuracy: 0.93 +- 0.02\n",
    "Precision: 0.93 +- 0.04\n",
    "Recall: 0.90 +- 0.05\n",
    "F1: 0.91 +- 0.03\n",
    "ROCAUC: 0.93 +- 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3433440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.94 +- 0.01\n",
      "Precision: 0.95 +- 0.01\n",
      "Recall: 0.89 +- 0.02\n",
      "F1: 0.92 +- 0.01\n",
      "ROCAUC: 0.93 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.94 +- 0.02\n",
      "Precision: 0.94 +- 0.04\n",
      "Recall: 0.89 +- 0.05\n",
      "F1: 0.91 +- 0.03\n",
      "ROCAUC: 0.93 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "nb1 = GaussianNB(var_smoothing=1e-9)\n",
    "validate(nb1, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e19b64",
   "metadata": {},
   "source": [
    "Akkurat som for DecisionTreeClassifier kjører vi først en kjøring med baseline tuning verdier for GaussianNB, slik at vi har et utgangspunkt å sammenligne med. Når vi ser på resultatene av baseline kjøringen for GaussianNB, så ser vi at det er veldig liten forskjell i resultatene mellom traning og validation delene av datasetet, men det noe større standard avik for validation delen. Dette tyder på at modellen ikke har store problemer med overfiting og derfor i utgangspunktet burde har god generell overføringsverdi.\n",
    "\n",
    "For tuning av GaussianNB er det kun et parameter som det er mulig å tune, dette er var_smoothing som er en parameter for å justere smoothing faktoren til modellen [5].\n",
    "\n",
    "ref:\n",
    "[5] \"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\", lest 20.09.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3658d3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.93 +- 0.01\n",
      "Precision: 0.95 +- 0.01\n",
      "Recall: 0.87 +- 0.02\n",
      "F1: 0.91 +- 0.01\n",
      "ROCAUC: 0.92 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.94 +- 0.02\n",
      "Precision: 0.96 +- 0.03\n",
      "Recall: 0.86 +- 0.06\n",
      "F1: 0.91 +- 0.04\n",
      "ROCAUC: 0.92 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "nb2 = GaussianNB(var_smoothing=1e-8)\n",
    "validate(nb2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8328f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.93 +- 0.01\n",
      "Precision: 0.97 +- 0.01\n",
      "Recall: 0.84 +- 0.02\n",
      "F1: 0.90 +- 0.01\n",
      "ROCAUC: 0.91 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.97 +- 0.02\n",
      "Recall: 0.84 +- 0.05\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.91 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "nb3 = GaussianNB(var_smoothing=1e-7)\n",
    "validate(nb3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91fed950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.94 +- 0.01\n",
      "Precision: 0.94 +- 0.02\n",
      "Recall: 0.89 +- 0.02\n",
      "F1: 0.92 +- 0.01\n",
      "ROCAUC: 0.93 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.94 +- 0.02\n",
      "Precision: 0.92 +- 0.04\n",
      "Recall: 0.91 +- 0.04\n",
      "F1: 0.92 +- 0.03\n",
      "ROCAUC: 0.93 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "nb4 = GaussianNB(var_smoothing=1e-10)\n",
    "validate(nb4, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88dc8fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Accuracy: 0.94 +- 0.01\n",
      "Precision: 0.94 +- 0.01\n",
      "Recall: 0.90 +- 0.02\n",
      "F1: 0.92 +- 0.01\n",
      "ROCAUC: 0.93 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.92 +- 0.04\n",
      "Recall: 0.89 +- 0.04\n",
      "F1: 0.91 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "nb5 = GaussianNB(var_smoothing=1e-14)\n",
    "validate(nb5, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc055c",
   "metadata": {},
   "source": [
    "Etter å ha gjennomført testing og validering med forskjellige verdier for var_smoothing har jeg valgt å bruke \"nb4\" da denne ga meg best resultater sammenlignet med baseline. Det også denne jeg kommer til sammeligne opp mot DecisionTreeClassifier. nb4 ble kjørt med følgende verdier. nb4 = GaussianNB(var_smoothing=1e-10).\n",
    "\n",
    "Når vi sammenligner resultatene mellom \"nb1\" og \"nb4\" så ser vi at begge modellene har relativt små forskjeller i resulatene mellom traning og validerings delen av datasetet, noe som tyde på at begge modellene i liten grad overfiter til trenings datasetet. Når vi ser videre på resultatene har \"nb4\" fått en forbedring i recall, men også en reduksjon i precision kontra \"nb1\". Dette kan dermed tyde på at \"nb4\" har blitt bedre til å oppdage flest mulige \"positive\" tilfeller, men på bekostning av presisjonen til alle \"positive\" prediksjoner dvs. at den predikere noen flere falske \"positive\" tilfeller. Som nevnt tidligere så er dette godt innenfor forventet variasjon når vi ser på verdiene for standard avikene så det er viktig å ikke tolke disse endringene for sterkt.\n",
    "\n",
    "nb1 (baseline):\n",
    "Training results:\n",
    "Accuracy: 0.94 +- 0.01\n",
    "Precision: 0.95 +- 0.01\n",
    "Recall: 0.89 +- 0.02\n",
    "F1: 0.92 +- 0.01\n",
    "ROCAUC: 0.93 +- 0.01\n",
    "************************\n",
    "Validation results:\n",
    "Accuracy: 0.94 +- 0.02\n",
    "Precision: 0.94 +- 0.04\n",
    "Recall: 0.89 +- 0.05\n",
    "F1: 0.91 +- 0.03\n",
    "ROCAUC: 0.93 +- 0.03\n",
    "\n",
    "nb4:\n",
    "Training results:\n",
    "Accuracy: 0.94 +- 0.01\n",
    "Precision: 0.94 +- 0.02\n",
    "Recall: 0.89 +- 0.02\n",
    "F1: 0.92 +- 0.01\n",
    "ROCAUC: 0.93 +- 0.01\n",
    "************************\n",
    "Validation results:\n",
    "Accuracy: 0.94 +- 0.02\n",
    "Precision: 0.92 +- 0.04\n",
    "Recall: 0.91 +- 0.04\n",
    "F1: 0.92 +- 0.03\n",
    "ROCAUC: 0.93 +- 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1806682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier:\n",
      "Training results:\n",
      "Accuracy: 0.97 +- 0.01\n",
      "Precision: 0.98 +- 0.02\n",
      "Recall: 0.94 +- 0.03\n",
      "F1: 0.96 +- 0.01\n",
      "ROCAUC: 0.96 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.92 +- 0.05\n",
      "Recall: 0.89 +- 0.06\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.03\n",
      "************************\n",
      "Test results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.93 +- 0.05\n",
      "Recall: 0.88 +- 0.06\n",
      "F1: 0.90 +- 0.03\n",
      "ROCAUC: 0.92 +- 0.03\n",
      "\n",
      "***************\n",
      "\n",
      "GaussianNB:\n",
      "Training results:\n",
      "Accuracy: 0.94 +- 0.01\n",
      "Precision: 0.94 +- 0.02\n",
      "Recall: 0.90 +- 0.02\n",
      "F1: 0.92 +- 0.01\n",
      "ROCAUC: 0.93 +- 0.01\n",
      "************************\n",
      "Validation results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.92 +- 0.04\n",
      "Recall: 0.90 +- 0.04\n",
      "F1: 0.91 +- 0.03\n",
      "ROCAUC: 0.93 +- 0.02\n",
      "************************\n",
      "Test results:\n",
      "Accuracy: 0.93 +- 0.02\n",
      "Precision: 0.92 +- 0.04\n",
      "Recall: 0.90 +- 0.04\n",
      "F1: 0.91 +- 0.03\n",
      "ROCAUC: 0.93 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"DecisionTreeClassifier:\")\n",
    "validate(dt10, 50)\n",
    "test(dt10, 50)\n",
    "print(\"\\n***************\\n\")\n",
    "print(\"GaussianNB:\")\n",
    "validate(nb4, 50)\n",
    "test(nb4, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcac997",
   "metadata": {},
   "source": [
    "Når vi sammenligner modellene for DecisionTreeClassifier og GaussianNB ser vi at det er betydelig større variasjon mellom resultatene for traning, validation og test delene av datasetet for DecisionTreeClassifier, spesielt mellom traing og de andre delene av datasetet.Når vi ser på forskjellige mellom validation og test delene av datasette så er disse mye mindre enn opp mot resultatene for traning delen. Dette indikere at DecisionTreeClassifier modellen problemer med overfiting i forhold til traning delen av modellen, men vi har imidlertid forbedret dette noe gjennom tuningen av modellen.\n",
    "Når vi ser på resultatene for GaussianNB så er vi at det er mye mindre forskjeller i resulatatene mellom traning, validation og test dette inkidere at modellen i liten grad har problemer med overfiting i forhold til treningen av modell og derfor har bedre generell overføringverdi til andre data.\n",
    "\n",
    "Når vi også sammenligner de endelige test resultatene mellom DecisionTreeClassifier og GaussianNB, så ser vi at GaussianNB har like eller bedre resultater for alle målene bortsett fra for precision hvor DecisionTreeClassifier ligger et knep forann, men hvis vi ser på standard avikene så ser vi at GaussianNB har mindre standard avik for både precision og recall enn DecisionTreeClassifier og derfor vil ha mindre variasjon i disse verdiene ved flere kjøring av modellen. Jeg har valgt å bruke looping ved kjøring av modellen slik at jeg har fått resultater med mindre variasjonn og standard avik for å kunne ha et mål på den forvented variasjonen. Jeg ladet på å bruke 50 runder for hver modell, men det er forsatt betydelig variasjon pga. den randomiserte oppdeling av datasetet ved oppdeling til traning, validation og test. Ved flere kjøring vil derfor resulatene kunne variere betydelig.\n",
    "\n",
    "Totaltsett lader jeg på at GaussianNB vil være en bedre modelle for disse dataene, både på grunn av litt bedre resultater totaltset, men også pga mindre risiko for overfiting av modellen ved treningen.\n",
    "Når vi ser på datatypene som featuresene i datasetet innehold er dette ikke så overraskende da alle disse virker å være normalfordelte tallverdier som vil passe veldig godt til bruk i GaussianNB modellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad9a2e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
