{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221c8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.metrics import make_scorer, get_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21532bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"..\\oblig3_og_4\\student_performance.csv\", delimiter=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b5b5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "#targets = encoder.fit_transform(df[['Target']])\n",
    "targets = pd.Series(LabelEncoder().fit_transform(df['Target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5684b398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       2\n",
       "2       0\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "4419    2\n",
       "4420    0\n",
       "4421    0\n",
       "4422    2\n",
       "4423    2\n",
       "Length: 4424, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5debee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(StandardScaler().fit_transform(df.drop('Target', axis=1)), columns=df.drop('Target', axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e71e3e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 1st sem (without evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-0.095470</td>\n",
       "      <td>2.490896</td>\n",
       "      <td>-4.209520</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-0.804841</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>-0.036018</td>\n",
       "      <td>-0.669778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-2.838337</td>\n",
       "      <td>-2.042630</td>\n",
       "      <td>-1.471527</td>\n",
       "      <td>-1.963489</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.287638</td>\n",
       "      <td>0.124386</td>\n",
       "      <td>0.765761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-0.209869</td>\n",
       "      <td>-0.554068</td>\n",
       "      <td>0.192580</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>2.076819</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>-1.189759</td>\n",
       "      <td>-1.256427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>-0.522682</td>\n",
       "      <td>0.518904</td>\n",
       "      <td>0.659562</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>-1.105222</td>\n",
       "      <td>0.347199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-1.010660</td>\n",
       "      <td>2.490896</td>\n",
       "      <td>0.103404</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-0.804841</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>1.117723</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>-2.042630</td>\n",
       "      <td>-1.471527</td>\n",
       "      <td>-1.963489</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.287638</td>\n",
       "      <td>0.124386</td>\n",
       "      <td>0.765761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-0.095470</td>\n",
       "      <td>0.207173</td>\n",
       "      <td>0.444115</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-0.804841</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>1.181819</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>0.490616</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.416450</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.813253</td>\n",
       "      <td>-1.466871</td>\n",
       "      <td>-1.375511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.356212</td>\n",
       "      <td>1.162916</td>\n",
       "      <td>-0.554068</td>\n",
       "      <td>-0.408389</td>\n",
       "      <td>-2.856470</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-2.473171</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>1.117723</td>\n",
       "      <td>1.024985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>-0.522682</td>\n",
       "      <td>0.518904</td>\n",
       "      <td>0.531608</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>-1.105222</td>\n",
       "      <td>0.347199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-1.010660</td>\n",
       "      <td>3.252137</td>\n",
       "      <td>0.444115</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-0.577342</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>-1.189759</td>\n",
       "      <td>-1.386793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>-0.016033</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.467631</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>1.476924</td>\n",
       "      <td>1.137005</td>\n",
       "      <td>-1.789667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-1.010660</td>\n",
       "      <td>0.207173</td>\n",
       "      <td>0.444115</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>-0.956508</td>\n",
       "      <td>14.916228</td>\n",
       "      <td>-1.189759</td>\n",
       "      <td>-1.386793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>-0.522682</td>\n",
       "      <td>-0.808050</td>\n",
       "      <td>0.147747</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.175007</td>\n",
       "      <td>-0.454253</td>\n",
       "      <td>0.889126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-1.010660</td>\n",
       "      <td>-0.554068</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>1.621820</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>1.117723</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>0.805144</td>\n",
       "      <td>0.237291</td>\n",
       "      <td>-1.139788</td>\n",
       "      <td>0.627573</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>-1.105222</td>\n",
       "      <td>0.347199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-1.010660</td>\n",
       "      <td>-0.554068</td>\n",
       "      <td>0.140722</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>3.593483</td>\n",
       "      <td>-0.126298</td>\n",
       "      <td>1.117723</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.561161</td>\n",
       "      <td>-0.522682</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.339678</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.813253</td>\n",
       "      <td>-1.466871</td>\n",
       "      <td>-1.375511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>-0.294829</td>\n",
       "      <td>-0.495866</td>\n",
       "      <td>-0.554068</td>\n",
       "      <td>0.444115</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>-0.35023</td>\n",
       "      <td>1.470154</td>\n",
       "      <td>2.911135</td>\n",
       "      <td>1.181819</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>-0.522682</td>\n",
       "      <td>0.518904</td>\n",
       "      <td>0.531608</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.425695</td>\n",
       "      <td>1.787974</td>\n",
       "      <td>-0.749872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4424 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Marital status  Application mode  Application order    Course  \\\n",
       "0          -0.294829         -0.095470           2.490896 -4.209520   \n",
       "1          -0.294829         -0.209869          -0.554068  0.192580   \n",
       "2          -0.294829         -1.010660           2.490896  0.103404   \n",
       "3          -0.294829         -0.095470           0.207173  0.444115   \n",
       "4           1.356212          1.162916          -0.554068 -0.408389   \n",
       "...              ...               ...                ...       ...   \n",
       "4419       -0.294829         -1.010660           3.252137  0.444115   \n",
       "4420       -0.294829         -1.010660           0.207173  0.444115   \n",
       "4421       -0.294829         -1.010660          -0.554068  0.311805   \n",
       "4422       -0.294829         -1.010660          -0.554068  0.140722   \n",
       "4423       -0.294829         -0.495866          -0.554068  0.444115   \n",
       "\n",
       "      Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                         0.350082                -0.35023   \n",
       "1                         0.350082                -0.35023   \n",
       "2                         0.350082                -0.35023   \n",
       "3                         0.350082                -0.35023   \n",
       "4                        -2.856470                -0.35023   \n",
       "...                            ...                     ...   \n",
       "4419                      0.350082                -0.35023   \n",
       "4420                      0.350082                -0.35023   \n",
       "4421                      0.350082                -0.35023   \n",
       "4422                      0.350082                -0.35023   \n",
       "4423                      0.350082                -0.35023   \n",
       "\n",
       "      Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                          -0.804841    -0.126298               -0.036018   \n",
       "1                           2.076819    -0.126298               -1.189759   \n",
       "2                          -0.804841    -0.126298                1.117723   \n",
       "3                          -0.804841    -0.126298                1.181819   \n",
       "4                          -2.473171    -0.126298                1.117723   \n",
       "...                              ...          ...                     ...   \n",
       "4419                       -0.577342    -0.126298               -1.189759   \n",
       "4420                       -0.956508    14.916228               -1.189759   \n",
       "4421                        1.621820    -0.126298                1.117723   \n",
       "4422                        3.593483    -0.126298                1.117723   \n",
       "4423                        1.470154     2.911135                1.181819   \n",
       "\n",
       "      Father's qualification  ...  \\\n",
       "0                  -0.669778  ...   \n",
       "1                  -1.256427  ...   \n",
       "2                   0.959802  ...   \n",
       "3                   0.959802  ...   \n",
       "4                   1.024985  ...   \n",
       "...                      ...  ...   \n",
       "4419               -1.386793  ...   \n",
       "4420               -1.386793  ...   \n",
       "4421                0.959802  ...   \n",
       "4422                0.959802  ...   \n",
       "4423                0.959802  ...   \n",
       "\n",
       "      Curricular units 1st sem (without evaluations)  \\\n",
       "0                                          -0.199273   \n",
       "1                                          -0.199273   \n",
       "2                                          -0.199273   \n",
       "3                                          -0.199273   \n",
       "4                                          -0.199273   \n",
       "...                                              ...   \n",
       "4419                                       -0.199273   \n",
       "4420                                       -0.199273   \n",
       "4421                                       -0.199273   \n",
       "4422                                       -0.199273   \n",
       "4423                                       -0.199273   \n",
       "\n",
       "      Curricular units 2nd sem (credited)  \\\n",
       "0                               -0.282442   \n",
       "1                               -0.282442   \n",
       "2                               -0.282442   \n",
       "3                               -0.282442   \n",
       "4                               -0.282442   \n",
       "...                                   ...   \n",
       "4419                            -0.282442   \n",
       "4420                            -0.282442   \n",
       "4421                            -0.282442   \n",
       "4422                            -0.282442   \n",
       "4423                            -0.282442   \n",
       "\n",
       "      Curricular units 2nd sem (enrolled)  \\\n",
       "0                               -2.838337   \n",
       "1                               -0.105726   \n",
       "2                               -0.105726   \n",
       "3                               -0.105726   \n",
       "4                               -0.105726   \n",
       "...                                   ...   \n",
       "4419                            -0.105726   \n",
       "4420                            -0.105726   \n",
       "4421                             0.805144   \n",
       "4422                            -0.561161   \n",
       "4423                            -0.105726   \n",
       "\n",
       "      Curricular units 2nd sem (evaluations)  \\\n",
       "0                                  -2.042630   \n",
       "1                                  -0.522682   \n",
       "2                                  -2.042630   \n",
       "3                                   0.490616   \n",
       "4                                  -0.522682   \n",
       "...                                      ...   \n",
       "4419                               -0.016033   \n",
       "4420                               -0.522682   \n",
       "4421                                0.237291   \n",
       "4422                               -0.522682   \n",
       "4423                               -0.522682   \n",
       "\n",
       "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                               -1.471527                         -1.963489   \n",
       "1                                0.518904                          0.659562   \n",
       "2                               -1.471527                         -1.963489   \n",
       "3                                0.187165                          0.416450   \n",
       "4                                0.518904                          0.531608   \n",
       "...                                   ...                               ...   \n",
       "4419                             0.187165                          0.467631   \n",
       "4420                            -0.808050                          0.147747   \n",
       "4421                            -1.139788                          0.627573   \n",
       "4422                             0.187165                          0.339678   \n",
       "4423                             0.518904                          0.531608   \n",
       "\n",
       "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                          -0.199441          -0.287638   \n",
       "1                                          -0.199441           0.876222   \n",
       "2                                          -0.199441          -0.287638   \n",
       "3                                          -0.199441          -0.813253   \n",
       "4                                          -0.199441           0.876222   \n",
       "...                                              ...                ...   \n",
       "4419                                       -0.199441           1.476924   \n",
       "4420                                       -0.199441          -0.175007   \n",
       "4421                                       -0.199441           0.876222   \n",
       "4422                                       -0.199441          -0.813253   \n",
       "4423                                       -0.199441           0.425695   \n",
       "\n",
       "      Inflation rate       GDP  \n",
       "0           0.124386  0.765761  \n",
       "1          -1.105222  0.347199  \n",
       "2           0.124386  0.765761  \n",
       "3          -1.466871 -1.375511  \n",
       "4          -1.105222  0.347199  \n",
       "...              ...       ...  \n",
       "4419        1.137005 -1.789667  \n",
       "4420       -0.454253  0.889126  \n",
       "4421       -1.105222  0.347199  \n",
       "4422       -1.466871 -1.375511  \n",
       "4423        1.787974 -0.749872  \n",
       "\n",
       "[4424 rows x 36 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea58a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0c5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4424, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee36daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_random_state = 15\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': get_scorer('accuracy'),\n",
    "    'precision': make_scorer(precision_score, average='macro', zero_division=1.0),\n",
    "    'recall': make_scorer(recall_score, average='macro', zero_division=1.0),\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'roc_auc': make_scorer(roc_auc_score, multi_class='ovr', average='macro', response_method='predict')   \n",
    "}\n",
    "\n",
    "def evaluate(estimator, X, y):\n",
    "    scores = {}\n",
    "    for (name,scorer) in scoring.items():\n",
    "        scores[name] = scorer(estimator, X, y) \n",
    "    return scores\n",
    "\n",
    "def train(features, targets, estimator, params, scoring=scoring, refit='f1', random_state=global_random_state, outer_splits=5, inner_splits=4):\n",
    "\n",
    "    outer_cv = KFold(n_splits=outer_splits, shuffle=True, random_state=global_random_state)\n",
    "    inner_cv = KFold(n_splits=inner_splits, shuffle=True, random_state=global_random_state)\n",
    "\n",
    "    scores_train = []\n",
    "    scores_test = []\n",
    "    estimators = []\n",
    "    cv_results = []\n",
    "\n",
    "    # Loop through all test folds\n",
    "    for (train_index, test_index) in outer_cv.split(features, targets):\n",
    "        \n",
    "        grid = GridSearchCV(\n",
    "            estimator,\n",
    "            params, \n",
    "            scoring=scoring, \n",
    "            refit=refit,\n",
    "            error_score='raise', \n",
    "            cv=inner_cv)\n",
    "        grid.fit(features.iloc[train_index], targets[train_index])        \n",
    "        \n",
    "        evaluation_train = evaluate(grid, features.iloc[train_index], targets[train_index])\n",
    "        evaluation_test = evaluate(grid, features.iloc[test_index], targets[test_index])\n",
    "        \n",
    "        scores_train.append(evaluation_train)\n",
    "        scores_test.append(evaluation_test)\n",
    "        \n",
    "        estimators.append(grid.best_estimator_)\n",
    "        cv_results.append(pd.DataFrame(grid.cv_results_))\n",
    "        print(\"*\")\n",
    "\n",
    "    return estimators, pd.DataFrame(scores_train), pd.DataFrame(scores_test), pd.concat(cv_results, names=['test_split'], keys=range(outer_splits))\n",
    "\n",
    "def print_estimators(estimators):\n",
    "    for estimatior in estimators:\n",
    "        print(estimatior)\n",
    "\n",
    "def create_model(optimizer=\"adam\", loss='sparse_categorical_crossentropy', activation='relu', layers=2, neurons=120):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(36,)))\n",
    "    for layer in range(1,layers+1):\n",
    "        model.add(Dense(int(neurons/layer), activation=activation))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2558c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d01de630",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAxisError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m keras_class_param = {\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m#'batch_size': [10],\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m#'epochs': [10],     \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel__neurons\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m80\u001b[39m],\n\u001b[32m      9\u001b[39m }\n\u001b[32m     10\u001b[39m keras_class_model = KerasClassifier(model=create_model, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m keras_estimators, keras_scores_train, keras_scores_test, keras_cv_results = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeras_class_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeras_class_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mouter_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(features, targets, estimator, params, scoring, refit, random_state, outer_splits, inner_splits)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m outer_cv.split(features, targets):\n\u001b[32m     30\u001b[39m     grid = GridSearchCV(\n\u001b[32m     31\u001b[39m         estimator,\n\u001b[32m     32\u001b[39m         params, \n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m         error_score=\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     36\u001b[39m         cv=inner_cv)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[32m     39\u001b[39m     evaluation_train = evaluate(grid, features.iloc[train_index], targets[train_index])\n\u001b[32m     40\u001b[39m     evaluation_test = evaluate(grid, features.iloc[test_index], targets[test_index])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:881\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    878\u001b[39m result[\u001b[33m\"\u001b[39m\u001b[33mfit_error\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    880\u001b[39m fit_time = time.time() - start_time\n\u001b[32m--> \u001b[39m\u001b[32m881\u001b[39m test_scores = \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_params_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    884\u001b[39m score_time = time.time() - start_time - fit_time\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:942\u001b[39m, in \u001b[36m_score\u001b[39m\u001b[34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[39m\n\u001b[32m    940\u001b[39m         scores = scorer(estimator, X_test, **score_params)\n\u001b[32m    941\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m         scores = \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[32m    945\u001b[39m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[32m    946\u001b[39m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:160\u001b[39m, in \u001b[36m_MultimetricScorer.__call__\u001b[39m\u001b[34m(self, estimator, *args, **kwargs)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raise_exc:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    162\u001b[39m         scores[name] = format_exc()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:152\u001b[39m, in \u001b[36m_MultimetricScorer.__call__\u001b[39m\u001b[34m(self, estimator, *args, **kwargs)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _BaseScorer):\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m         score = \u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    156\u001b[39m         score = scorer(estimator, *args, **routed_params.get(name).score)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:408\u001b[39m, in \u001b[36m_Scorer._score\u001b[39m\u001b[34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[39m\n\u001b[32m    400\u001b[39m y_pred = method_caller(\n\u001b[32m    401\u001b[39m     estimator,\n\u001b[32m    402\u001b[39m     _get_response_method_name(response_method),\n\u001b[32m    403\u001b[39m     X,\n\u001b[32m    404\u001b[39m     pos_label=pos_label,\n\u001b[32m    405\u001b[39m )\n\u001b[32m    407\u001b[39m scoring_kwargs = {**\u001b[38;5;28mself\u001b[39m._kwargs, **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sign * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_score_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscoring_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:680\u001b[39m, in \u001b[36mroc_auc_score\u001b[39m\u001b[34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[39m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m multi_class == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    679\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mmulti_class must be in (\u001b[39m\u001b[33m'\u001b[39m\u001b[33movo\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33movr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m680\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiclass_roc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    684\u001b[39m     labels = np.unique(y_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:752\u001b[39m, in \u001b[36m_multiclass_roc_auc_score\u001b[39m\u001b[34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Multiclass roc auc score.\u001b[39;00m\n\u001b[32m    707\u001b[39m \n\u001b[32m    708\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    749\u001b[39m \n\u001b[32m    750\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    751\u001b[39m \u001b[38;5;66;03m# validation of the input y_score\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m752\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.allclose(\u001b[32m1\u001b[39m, \u001b[43my_score\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[32m    753\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    754\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTarget scores need to be probabilities for multiclass \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    755\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mroc_auc, i.e. they should sum up to 1.0 over classes\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    756\u001b[39m     )\n\u001b[32m    758\u001b[39m \u001b[38;5;66;03m# validation for multiclass parameter specifications\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hallo\\Documents\\GitHub\\praktisk-maskinlering\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:51\u001b[39m, in \u001b[36m_sum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     50\u001b[39m          initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAxisError\u001b[39m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "keras_class_param = {\n",
    "    #'batch_size': [10],\n",
    "    #'epochs': [10],     \n",
    "    'model__optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    #'model__activation': ['relu', 'tanh', 'sigmoid'], \n",
    "    'model__loss': ['sparse_categorical_crossentropy'], # husk legg til komentar pÃ¥ hvorfor du kun bruker denne.\n",
    "    'model__layers': [3],\n",
    "    'model__neurons': [80],\n",
    "}\n",
    "keras_class_model = KerasClassifier(model=create_model, verbose=0)\n",
    "keras_estimators, keras_scores_train, keras_scores_test, keras_cv_results = train(features, targets, keras_class_model, keras_class_param, outer_splits=3, inner_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "71c3822e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='param_model__activation', ylabel='mean_test_f1'>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "sb.boxplot(data=keras_cv_results, x='param_model__optimizer', y='mean_test_f1', ax=ax[0])\n",
    "sb.boxplot(data=keras_cv_results, x='param_model__activation', y='mean_test_f1', ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "0dbd900b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.748023</td>\n",
       "      <td>0.660759</td>\n",
       "      <td>0.648791</td>\n",
       "      <td>0.648777</td>\n",
       "      <td>0.755264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.781921</td>\n",
       "      <td>0.738792</td>\n",
       "      <td>0.692327</td>\n",
       "      <td>0.700875</td>\n",
       "      <td>0.783623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.771751</td>\n",
       "      <td>0.705002</td>\n",
       "      <td>0.689762</td>\n",
       "      <td>0.694968</td>\n",
       "      <td>0.783534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770621</td>\n",
       "      <td>0.731696</td>\n",
       "      <td>0.704619</td>\n",
       "      <td>0.711628</td>\n",
       "      <td>0.790253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.678599</td>\n",
       "      <td>0.652764</td>\n",
       "      <td>0.650675</td>\n",
       "      <td>0.754550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1   roc_auc\n",
       "0  0.748023   0.660759  0.648791  0.648777  0.755264\n",
       "1  0.781921   0.738792  0.692327  0.700875  0.783623\n",
       "2  0.771751   0.705002  0.689762  0.694968  0.783534\n",
       "3  0.770621   0.731696  0.704619  0.711628  0.790253\n",
       "4  0.742081   0.678599  0.652764  0.650675  0.754550"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4979e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KerasClassifier(\n",
       " \tmodel=<function create_model at 0x0000024F2C4A7E20>\n",
       " \tbuild_fn=None\n",
       " \twarm_start=False\n",
       " \trandom_state=None\n",
       " \toptimizer=rmsprop\n",
       " \tloss=None\n",
       " \tmetrics=None\n",
       " \tbatch_size=10\n",
       " \tvalidation_batch_size=None\n",
       " \tverbose=0\n",
       " \tcallbacks=None\n",
       " \tvalidation_split=0.0\n",
       " \tshuffle=True\n",
       " \trun_eagerly=False\n",
       " \tepochs=10\n",
       " \tclass_weight=None\n",
       " \tmodel__activation=sigmoid\n",
       " \tmodel__layers=3\n",
       " \tmodel__loss=categorical_crossentropy\n",
       " \tmodel__neurons=80\n",
       " \tmodel__optimizer=adam\n",
       " ),\n",
       " KerasClassifier(\n",
       " \tmodel=<function create_model at 0x0000024F2C4A7E20>\n",
       " \tbuild_fn=None\n",
       " \twarm_start=False\n",
       " \trandom_state=None\n",
       " \toptimizer=rmsprop\n",
       " \tloss=None\n",
       " \tmetrics=None\n",
       " \tbatch_size=10\n",
       " \tvalidation_batch_size=None\n",
       " \tverbose=0\n",
       " \tcallbacks=None\n",
       " \tvalidation_split=0.0\n",
       " \tshuffle=True\n",
       " \trun_eagerly=False\n",
       " \tepochs=10\n",
       " \tclass_weight=None\n",
       " \tmodel__activation=sigmoid\n",
       " \tmodel__layers=3\n",
       " \tmodel__loss=categorical_crossentropy\n",
       " \tmodel__neurons=80\n",
       " \tmodel__optimizer=rmsprop\n",
       " ),\n",
       " KerasClassifier(\n",
       " \tmodel=<function create_model at 0x0000024F2C4A7E20>\n",
       " \tbuild_fn=None\n",
       " \twarm_start=False\n",
       " \trandom_state=None\n",
       " \toptimizer=rmsprop\n",
       " \tloss=None\n",
       " \tmetrics=None\n",
       " \tbatch_size=10\n",
       " \tvalidation_batch_size=None\n",
       " \tverbose=0\n",
       " \tcallbacks=None\n",
       " \tvalidation_split=0.0\n",
       " \tshuffle=True\n",
       " \trun_eagerly=False\n",
       " \tepochs=10\n",
       " \tclass_weight=None\n",
       " \tmodel__activation=tanh\n",
       " \tmodel__layers=3\n",
       " \tmodel__loss=categorical_crossentropy\n",
       " \tmodel__neurons=80\n",
       " \tmodel__optimizer=adam\n",
       " ),\n",
       " KerasClassifier(\n",
       " \tmodel=<function create_model at 0x0000024F2C4A7E20>\n",
       " \tbuild_fn=None\n",
       " \twarm_start=False\n",
       " \trandom_state=None\n",
       " \toptimizer=rmsprop\n",
       " \tloss=None\n",
       " \tmetrics=None\n",
       " \tbatch_size=10\n",
       " \tvalidation_batch_size=None\n",
       " \tverbose=0\n",
       " \tcallbacks=None\n",
       " \tvalidation_split=0.0\n",
       " \tshuffle=True\n",
       " \trun_eagerly=False\n",
       " \tepochs=10\n",
       " \tclass_weight=None\n",
       " \tmodel__activation=sigmoid\n",
       " \tmodel__layers=3\n",
       " \tmodel__loss=categorical_crossentropy\n",
       " \tmodel__neurons=80\n",
       " \tmodel__optimizer=adam\n",
       " ),\n",
       " KerasClassifier(\n",
       " \tmodel=<function create_model at 0x0000024F2C4A7E20>\n",
       " \tbuild_fn=None\n",
       " \twarm_start=False\n",
       " \trandom_state=None\n",
       " \toptimizer=rmsprop\n",
       " \tloss=None\n",
       " \tmetrics=None\n",
       " \tbatch_size=10\n",
       " \tvalidation_batch_size=None\n",
       " \tverbose=0\n",
       " \tcallbacks=None\n",
       " \tvalidation_split=0.0\n",
       " \tshuffle=True\n",
       " \trun_eagerly=False\n",
       " \tepochs=10\n",
       " \tclass_weight=None\n",
       " \tmodel__activation=relu\n",
       " \tmodel__layers=3\n",
       " \tmodel__loss=categorical_crossentropy\n",
       " \tmodel__neurons=80\n",
       " \tmodel__optimizer=rmsprop\n",
       " )]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d02b2bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "keras_class_param_2 = {\n",
    "    'batch_size': [10],\n",
    "    'epochs': [10],     \n",
    "    'model__optimizer': ['adam'],\n",
    "    'model__activation': ['relu'], \n",
    "    'model__loss': ['categorical_crossentropy'],\n",
    "    'model__layers': [3, 4],\n",
    "    'model__neurons': [80, 120],\n",
    "}\n",
    "keras_class_model_2 = KerasClassifier(model=create_model, verbose=0)\n",
    "keras_estimators_2, keras_scores_train_2, keras_scores_test_2, keras_cv_results_2 = train(features, targets, keras_class_model_2, keras_class_param_2, outer_splits=5, inner_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "f4431a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='param_model__neurons', ylabel='mean_test_f1'>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "sb.boxplot(data=keras_cv_results_2, x='param_model__layers', y='mean_test_f1', ax=ax[0])\n",
    "sb.boxplot(data=keras_cv_results_2, x='param_model__neurons', y='mean_test_f1', ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c2841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.654505</td>\n",
       "      <td>0.643163</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.751466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.789831</td>\n",
       "      <td>0.742528</td>\n",
       "      <td>0.720983</td>\n",
       "      <td>0.725049</td>\n",
       "      <td>0.803574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770621</td>\n",
       "      <td>0.715170</td>\n",
       "      <td>0.702549</td>\n",
       "      <td>0.702886</td>\n",
       "      <td>0.791187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.692161</td>\n",
       "      <td>0.659389</td>\n",
       "      <td>0.662896</td>\n",
       "      <td>0.763537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.725551</td>\n",
       "      <td>0.672720</td>\n",
       "      <td>0.680140</td>\n",
       "      <td>0.768017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1   roc_auc\n",
       "0  0.745763   0.654505  0.643163  0.642336  0.751466\n",
       "1  0.789831   0.742528  0.720983  0.725049  0.803574\n",
       "2  0.770621   0.715170  0.702549  0.702886  0.791187\n",
       "3  0.762712   0.692161  0.659389  0.662896  0.763537\n",
       "4  0.764706   0.725551  0.672720  0.680140  0.768017"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_scores_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "a686a4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KerasClassifier(\n",
       " \tmodel=<function create_model at 0x0000024F2C4A7E20>\n",
       " \tbuild_fn=None\n",
       " \twarm_start=False\n",
       " \trandom_state=None\n",
       " \toptimizer=rmsprop\n",
       " \tloss=None\n",
       " \tmetrics=None\n",
       " \tbatch_size=10\n",
       " \tvalidation_batch_size=None\n",
       " \tverbose=0\n",
       " \tcallbacks=None\n",
       " \tvalidation_split=0.0\n",
       " \tshuffle=True\n",
       " \trun_eagerly=False\n",
       " \tepochs=10\n",
       " \tclass_weight=None\n",
       " \tmodel__activation=sigmoid\n",
       " \tmodel__layers=4\n",
       " \tmodel__loss=categorical_crossentropy\n",
       " \tmodel__neurons=120\n",
       " \tmodel__optimizer=adam\n",
       " ),\n",
       " KerasClassifier(\n",
       " \tmodel=<function create_model at 0x0000024F2C4A7E20>\n",
       " \tbuild_fn=None\n",
       " \twarm_start=False\n",
       " \trandom_state=None\n",
       " \toptimizer=rmsprop\n",
       " \tloss=None\n",
       " \tmetrics=None\n",
       " \tbatch_size=10\n",
       " \tvalidation_batch_size=None\n",
       " \tverbose=0\n",
       " \tcallbacks=None\n",
       " \tvalidation_split=0.0\n",
       " \tshuffle=True\n",
       " \trun_eagerly=False\n",
       " \tepochs=10\n",
       " \tclass_weight=None\n",
       " \tmodel__activation=sigmoid\n",
       " \tmodel__layers=3\n",
       " \tmodel__loss=categorical_crossentropy\n",
       " \tmodel__neurons=80\n",
       " \tmodel__optimizer=adam\n",
       " ),\n",
       " KerasClassifier(\n",
       " \tmodel=<function create_model at 0x0000024F2C4A7E20>\n",
       " \tbuild_fn=None\n",
       " \twarm_start=False\n",
       " \trandom_state=None\n",
       " \toptimizer=rmsprop\n",
       " \tloss=None\n",
       " \tmetrics=None\n",
       " \tbatch_size=10\n",
       " \tvalidation_batch_size=None\n",
       " \tverbose=0\n",
       " \tcallbacks=None\n",
       " \tvalidation_split=0.0\n",
       " \tshuffle=True\n",
       " \trun_eagerly=False\n",
       " \tepochs=10\n",
       " \tclass_weight=None\n",
       " \tmodel__activation=sigmoid\n",
       " \tmodel__layers=3\n",
       " \tmodel__loss=categorical_crossentropy\n",
       " \tmodel__neurons=80\n",
       " \tmodel__optimizer=adam\n",
       " ),\n",
       " KerasClassifier(\n",
       " \tmodel=<function create_model at 0x0000024F2C4A7E20>\n",
       " \tbuild_fn=None\n",
       " \twarm_start=False\n",
       " \trandom_state=None\n",
       " \toptimizer=rmsprop\n",
       " \tloss=None\n",
       " \tmetrics=None\n",
       " \tbatch_size=10\n",
       " \tvalidation_batch_size=None\n",
       " \tverbose=0\n",
       " \tcallbacks=None\n",
       " \tvalidation_split=0.0\n",
       " \tshuffle=True\n",
       " \trun_eagerly=False\n",
       " \tepochs=10\n",
       " \tclass_weight=None\n",
       " \tmodel__activation=sigmoid\n",
       " \tmodel__layers=3\n",
       " \tmodel__loss=categorical_crossentropy\n",
       " \tmodel__neurons=80\n",
       " \tmodel__optimizer=adam\n",
       " ),\n",
       " KerasClassifier(\n",
       " \tmodel=<function create_model at 0x0000024F2C4A7E20>\n",
       " \tbuild_fn=None\n",
       " \twarm_start=False\n",
       " \trandom_state=None\n",
       " \toptimizer=rmsprop\n",
       " \tloss=None\n",
       " \tmetrics=None\n",
       " \tbatch_size=10\n",
       " \tvalidation_batch_size=None\n",
       " \tverbose=0\n",
       " \tcallbacks=None\n",
       " \tvalidation_split=0.0\n",
       " \tshuffle=True\n",
       " \trun_eagerly=False\n",
       " \tepochs=10\n",
       " \tclass_weight=None\n",
       " \tmodel__activation=sigmoid\n",
       " \tmodel__layers=4\n",
       " \tmodel__loss=categorical_crossentropy\n",
       " \tmodel__neurons=80\n",
       " \tmodel__optimizer=adam\n",
       " )]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_estimators_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
