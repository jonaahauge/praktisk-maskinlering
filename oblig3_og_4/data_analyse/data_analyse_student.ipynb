{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812094a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"..\\oblig3_og_4\\student_performance.csv\", delimiter=\";\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09804b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e4f25",
   "metadata": {},
   "source": [
    "### Beskrivelse av dataset:\n",
    "Datasettet består av 36 features/kolonner og en target/kolonne. Alle featurene er oppgitt i numeriske verdier, men flere har disse ser ut til å ha blitt transformert fra categoriske verdier/input og er ikke en del av en sammenhengende tallrekke. Hensikten med datasettet er å predikere akademisk frafall og si noe om hvilke features som påvirker dette. Hver rad i datasette representere en student.\n",
    "\n",
    "- Feature kolonnene inneholder forskjellig informasjon om akademsike, demografiske og sosial økonomiske faktorer som var kjent ved oppstart.\n",
    "\n",
    "- Target kolonnen oppgir 3 kategoriske verdier, Enrolled, Droppout og Graduated. Disse beskriver statusen studenten har ved avsluttning av normal vargihet for et fag.\n",
    "\n",
    "- Datasette skal ikke inneholde noen manglende verdier.\n",
    "\n",
    "- Det står også i beskrivelsen av datasette at det har blitt gjennomført en begtydelig preprossesering av datasettet for eventuelle uteliggere og manglende data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Target'].value_counts())\n",
    "df['Target'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e07b8aa",
   "metadata": {},
   "source": [
    "- Som vi ser av tellingen av kategoriene i target kolonnen, så er det noe skjevfordeling i antallet av de forskjellige kategoriene, men alle kategoriene er godt representert og ingen av katagoriene har et veldig lavt antall representasjoner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfecb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = pd.Series(LabelEncoder().fit_transform(df['Target']))\n",
    "print(df_targets.value_counts())\n",
    "df_targets.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8c768c",
   "metadata": {},
   "source": [
    "- Siden target kollonnen i utgangspunktet inneholdeholder kategoriskeverdier så må vi transformere disse før vi bruker datasette videre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1294e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df.drop(\"Target\", axis=1)\n",
    "df_features.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf11491",
   "metadata": {},
   "source": [
    "#### Histogram av feature kolonnene.\n",
    "- Histogrammet viser at det er betydelig forskjell i skalaene til de forskjellige featurene og det vil derfor være hensiktsmessig å gjennomføre en scalering slik at disse er repsresetert innenfor samme scalering. Jeg kommer til å bruke en standard mean scalering til å gjennomføre dette.\n",
    "\n",
    "- Vi ser også at datasettet inneholder en kobinasjon av kolonner med kontinuelige tallrekker og transformerte kategoriske data. Vi ser også at mange av kolonnen inneholder data som ikke er normalfordelt, men det er i utgangspunkt vansklig å gjøre noe med dette ut i fra sammensettning av datasetet uten å potensielt miste mye informasjon, det vil derfor være hensiksmessig å bruke modeller som ikke er avhenig av normalfordelete data for å prestere bra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47686ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(StandardScaler().fit_transform(df_features), columns=df_features.columns)\n",
    "df_features.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ffc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrolled = df[df['Target'] == 'Enrolled']\n",
    "df_dropout = df[df['Target'] == 'Dropout'].sample(len(df_enrolled))\n",
    "df_graduate = df[df['Target'] == 'Graduate'].sample(len(df_enrolled))\n",
    "\n",
    "df_downsample = pd.concat([df_enrolled, df_dropout, df_graduate])\n",
    "df_downsample = df_downsample.sample(frac=1)\n",
    "\n",
    "df_downsample_features = pd.DataFrame(StandardScaler().fit_transform(df_downsample.drop('Target', axis=1)), columns=df_downsample.drop('Target', axis=1).columns)\n",
    "df_downsample_target = pd.Series(LabelEncoder().fit_transform(df_downsample['Target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a486722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_downsample_target.value_counts())\n",
    "df_downsample_target.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebda85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(RandomForestClassifier(), X=df_downsample_features, y=df_downsample_target))\n",
    "print(cross_val_score(RandomForestClassifier(), X=df_features, y=df_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc2c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(GradientBoostingClassifier(), X=df_downsample_features, y=df_downsample_target))\n",
    "print(cross_val_score(GradientBoostingClassifier(), X=df_features, y=df_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(LogisticRegression(), X=df_downsample_features, y=df_downsample_target))\n",
    "print(cross_val_score(LogisticRegression(), X=df_features, y=df_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a2017",
   "metadata": {},
   "source": [
    "#### Test av downsampling på target kolonnen\n",
    "- Selvom alle kategoriene i target kolonnen har en god representasjon av verdier, så har jeg valg å gjennomføre en test av downsampling på datasettet for å se om dette kan gi noen positiv påvirking på treningen av datasettet.\n",
    "\n",
    "- For å gjennomføre downsamplingen har jeg downsamplet katagoriene for \"Graduated\" og \"Droppout\" mot antallet av verdier i \"Enrolled\", slik at disse er likt representert i datasettet. Deretter har jeg brukt cross_val_score til å gjennomføre en enkel test for å sammenligne downsampling og ikke for de modellene jeg planlegger å bruke videre i analysen.\n",
    "\n",
    "- Som vi kan se av resultatene i cellene over ga det ikke bedre resultater å gjennomføre en downsampling, så jeg kommer ikke til å bruke dette videre i analysen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlation = df_features.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "sb.heatmap(df_correlation, annot=True, cmap=\"coolwarm\", fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d53667",
   "metadata": {},
   "source": [
    "#### Korrelasjon\n",
    "- Som vi kan se av plotet over er det noen features som har en betydelig korrelasjon, jeg kommer defor til bruke PCA til å teste om noen eller flere av featurene kan kombineres for å redusere denne korrelasjonen, samt gjøre datasettet mindre og mindre tidskrevende å trene, tune og teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a74e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pca10 = pd.DataFrame(PCA(n_components=10).fit_transform(df_features))\n",
    "features_pca14 = pd.DataFrame(PCA(n_components=14).fit_transform(df_features))\n",
    "features_pca18 = pd.DataFrame(PCA(n_components=18).fit_transform(df_features))\n",
    "features_pca22 = pd.DataFrame(PCA(n_components=22).fit_transform(df_features))\n",
    "features_pca26 = pd.DataFrame(PCA(n_components=26).fit_transform(df_features))\n",
    "features_pca29 = pd.DataFrame(PCA(n_components=29).fit_transform(df_features))\n",
    "features_pca32 = pd.DataFrame(PCA(n_components=32).fit_transform(df_features))\n",
    "features_pca35 = pd.DataFrame(PCA(n_components=35).fit_transform(df_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36fce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(RandomForestClassifier(), X=features_pca10, y=df_targets))\n",
    "print(cross_val_score(RandomForestClassifier(), X=features_pca14, y=df_targets))\n",
    "print(cross_val_score(RandomForestClassifier(), X=features_pca18, y=df_targets))\n",
    "print(cross_val_score(RandomForestClassifier(), X=features_pca22, y=df_targets))\n",
    "print(cross_val_score(RandomForestClassifier(), X=features_pca26, y=df_targets))\n",
    "print(cross_val_score(RandomForestClassifier(), X=features_pca29, y=df_targets))\n",
    "print(cross_val_score(RandomForestClassifier(), X=features_pca32, y=df_targets))\n",
    "print(cross_val_score(RandomForestClassifier(), X=features_pca35, y=df_targets))\n",
    "print(cross_val_score(RandomForestClassifier(), X=df_features, y=df_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30125471",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(GradientBoostingClassifier(), X=features_pca10, y=df_targets))\n",
    "print(cross_val_score(GradientBoostingClassifier(), X=features_pca14, y=df_targets))\n",
    "print(cross_val_score(GradientBoostingClassifier(), X=features_pca18, y=df_targets))\n",
    "print(cross_val_score(GradientBoostingClassifier(), X=features_pca22, y=df_targets))\n",
    "print(cross_val_score(GradientBoostingClassifier(), X=features_pca26, y=df_targets))\n",
    "print(cross_val_score(GradientBoostingClassifier(), X=features_pca29, y=df_targets))\n",
    "print(cross_val_score(GradientBoostingClassifier(), X=features_pca32, y=df_targets))\n",
    "print(cross_val_score(GradientBoostingClassifier(), X=features_pca35, y=df_targets))\n",
    "print(cross_val_score(GradientBoostingClassifier(), X=df_features, y=df_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a2f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(LogisticRegression(), X=features_pca10, y=df_targets))\n",
    "print(cross_val_score(LogisticRegression(), X=features_pca14, y=df_targets))\n",
    "print(cross_val_score(LogisticRegression(), X=features_pca18, y=df_targets))\n",
    "print(cross_val_score(LogisticRegression(), X=features_pca22, y=df_targets))\n",
    "print(cross_val_score(LogisticRegression(), X=features_pca26, y=df_targets))\n",
    "print(cross_val_score(LogisticRegression(), X=features_pca29, y=df_targets))\n",
    "print(cross_val_score(LogisticRegression(), X=features_pca32, y=df_targets))\n",
    "print(cross_val_score(LogisticRegression(), X=features_pca35, y=df_targets))\n",
    "print(cross_val_score(LogisticRegression(), X=df_features, y=df_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d66f5",
   "metadata": {},
   "source": [
    "#### PCA testing\n",
    "- For å test ut som PCA kan gi bedre resultater for treningen av datasettet så har jeg bruket PCA til å samle datasette til ferre features, jeg valgt å test dette over en range (14-35, samt uendrett) for å se om gir noen positiv effekt på prestajonen for modellen på dette datasettet.\n",
    "\n",
    "- Akkurat som ved testing av downsampling har jeg bruk cross_val_score til å gjennoføre en enkelt testing for de modellene jeg har planer om å bruke videre.\n",
    "\n",
    "- Ut i fra resultatene som denne testingen gir, så ser det ikke ut til å være hensiktsmessig å bruke PCA på dette datasette videre i analysen i forhold til prestasjonen til datasettet da det ikke gir noen betydelig bedre resultater for noen av modellene. Vi ser også av resultatene at prestasjonene til datasettet generell er bedre desto flere av featurene som er bevart.\n",
    "\n",
    "- For LogisticRegession er det inmidlertid potensielt noe bedre resultat for en PCA kombinasjon med 32 features og hvis vi kun skulle ha jobbet videre med denne modellen vil dette vært hensikts messig å undersøke videre med videre tuneing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
